{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url(url):\n",
    "    # define proxyDict \n",
    "#     proxyDict = {\n",
    "#         \"http\": ,\n",
    "#         \"https\": ,\n",
    "#     }\n",
    "\n",
    "    resp = requests.get(url, timeout=3, stream=True, proxies=proxyDict).raw\n",
    "    arr = np.asarray(bytearray(resp.read()), dtype=np.uint8)\n",
    "    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(records):\n",
    "\n",
    "    image_files, image_arr_list = load_urls(records['url'])\n",
    "\n",
    "    rows = []\n",
    "    images = []\n",
    "    with futures.ProcessPoolExecutor(max_workers=(mp.cpu_count()-1)) as executor:\n",
    "        future_to_file = {executor.submit(feature_map, im_arr, None):\n",
    "                          img_file for img_file, im_arr in zip(image_files, image_arr_list)}\n",
    "        for future in futures.as_completed(future_to_file):\n",
    "            next_file = future_to_file[future]\n",
    "            try:\n",
    "                image_response = future.result()\n",
    "            except Exception as e:\n",
    "                print('%r generated an exception during image processing: %s' % (next_file, e))\n",
    "            else:\n",
    "                if image_response is None:\n",
    "                    print (\"no data loaded for url: {}\".format(next_file))\n",
    "                    continue\n",
    "                else:\n",
    "                    rows.append(next_file)\n",
    "                    images.append(image_response[0])\n",
    "\n",
    "\n",
    "    np.savez_compressed('_images.npz', features=images, records=rows)\n",
    "    # data = np.load('features.npz', allow_pickle=True)\n",
    "    # data['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from load_url import fetch_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_urls(file_list):\n",
    "    loop = asyncio.get_event_loop()  # event loop\n",
    "    future = asyncio.ensure_future(fetch_all(file_list))  # could be Whitespace\n",
    "    loop.run_until_complete(future)\n",
    "    file_list = future.result()[0]\n",
    "    image_arr_list = future.result()[1]\n",
    "    return file_list, image_arr_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
